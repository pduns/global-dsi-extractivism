{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add viruses as I accidently deleted them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.11. so some IDs seems to have been collected badly, need to check that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: folder=X:\\5_Research\\Paul\\dsi_origins\\\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "import pandas as pd \n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import glob\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pycountry \n",
    "import pycountry_convert as pc\n",
    "pp = pprint.PrettyPrinter()\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point, Polygon\n",
    "import regex as re\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "%env folder = X:\\5_Research\\Paul\\dsi_origins\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define path\n",
    "path = %env folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a494-nipw010\\AppData\\Local\\Temp\\ipykernel_9384\\4261549575.py:1: DtypeWarning: Columns (3,4,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_wildsi_idselect = pd.read_csv(path + R'processed_data\\wildsi_idselect.csv', index_col = 0)\n"
     ]
    }
   ],
   "source": [
    "df_wildsi_idselect = pd.read_csv(path + R'processed_data\\wildsi_idselect.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_wildsi_idselect.drop(columns = ['COUNTRY']).drop_duplicates().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. label taxon type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_species = pd.read_csv(path+R'processed_data\\2024-08-28_df_wildsi_with_ncbi_lineage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxid_skingdom= df_species[['Taxid','Superkingdom name']].drop_duplicates()\n",
    "taxid_skingdom_dict = dict(zip(list(df_taxid_skingdom['Taxid']),list(df_taxid_skingdom['Superkingdom name']))) \n",
    "df['skingdom'] = df['TAXID'].map(taxid_skingdom_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxid_species= df_species[['Taxid','Species name']].drop_duplicates()\n",
    "taxid_species_dict = dict(zip(list(df_taxid_species['Taxid']),list(df_taxid_species['Species name']))) \n",
    "df['species'] = df['TAXID'].map(taxid_species_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxid_genus= df_species[['Taxid','Genus name']].drop_duplicates()\n",
    "taxid_genus_dict = dict(zip(list(df_taxid_genus['Taxid']),list(df_taxid_genus['Genus name']))) \n",
    "df['genus'] = df['TAXID'].map(taxid_genus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxid_class= df_species[['Taxid','Class name']].drop_duplicates()\n",
    "taxid_class_dict = dict(zip(list(df_taxid_class['Taxid']),list(df_taxid_class['Class name']))) \n",
    "df['class'] = df['TAXID'].map(taxid_class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. label political context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get crops data\n",
    "#df_crop_genus = pd.read_csv(path+R'raw_data\\mapping_TREATY_ANNEX1_to_NCBI_GENUS.csv') #these taxids do not result in any matches as they are too broad --> need to use the subspecies dataset\n",
    "df_crop_genus_sub = pd.read_csv(path+R'raw_data\\subtaxa_for_TREATY_ANNEX1_in_NCBI.cvs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_list = list(df_crop_genus_sub['NCBI_GENUS_SUB_TAXID'])\n",
    "taxid_list = list(df['TAXID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crop_labels = [1 if x in crop_list else 0 for x in taxid_list]\n",
    "\n",
    "df['crops'] = crop_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathogens\n",
    "df_pathogens = pd.read_excel(path+R'raw_data\\pathogens.xls')\n",
    "pathogens_list = list(df_pathogens['TAXID'])\n",
    "\n",
    "pathogen_labels = [1 if x in pathogens_list else 0 for x in taxid_list]\n",
    "\n",
    "df['pathogens'] = pathogen_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oikopleura (Vexillaria) dioica\n",
      "Halichondria (Halichondria) okadai\n",
      "Doryteuthis (Amerigo) pealeii\n",
      "Holothuria (Mertensiothuria) leucospilota\n",
      "Sipunculus (Sipunculus) nudus\n",
      "Lepas (Anatifa) anatifera\n",
      "300000\n",
      "600000\n",
      "1200000\n"
     ]
    }
   ],
   "source": [
    "# open the patent marine species data\n",
    "df_pat = pd.read_excel(R'X:\\5_Research\\Paul\\data\\Patent_species_v4.xlsx')\n",
    "\n",
    "# open the species data\n",
    "df_pat_m = df_pat[df_pat['Marine YES'] == 'X'] \n",
    "\n",
    "#prepare the species names\n",
    "pat_species_raw = list(set(df_pat_m['ScientificName_accepted'].dropna()))\n",
    "\n",
    "# take > out\n",
    "pat_species_ls = [x.split()[0] if \">\" in x else x for x in pat_species_raw]\n",
    "\n",
    "pat_cleaned_species_dup = []\n",
    "for organism in pat_species_ls:\n",
    "        if '(' in organism and len(organism.split()) >= 3: \n",
    "            print(organism)\n",
    "\n",
    "#1) If two words, query it as it's written\n",
    "#2) If one word, add either \"sp.\" (one species) or \"spp.\" (mix of species), it is used for cases when species have not been identified fully. Be aware that the dot after the abbreviation could be missing.\n",
    "#3) If three words, query it as it's written, and shorten it to two words if you retrieve zero results --> it would never be the case. so I will do both three words and the two word version right away\n",
    "\n",
    "\n",
    "\n",
    "## prepare: 2 words = 2 words; 1 word = word+ sp; 3 words == 3 words + 2 words\n",
    "pat_cleaned_species_dup = []\n",
    "for organism in pat_species_ls:\n",
    "        #print(organism)\n",
    "\n",
    "        #1 word = word+ sp:\n",
    "        if len(organism.split()) == 1:\n",
    "            pat_cleaned_species_dup.append(organism+' sp')\n",
    "            #print('edited: '+organism+' sp')\n",
    "        #3+ words == 3+ words + 2 words\n",
    "        elif len(organism.split()) >= 3: \n",
    "            pat_cleaned_species_dup.append(organism)\n",
    "            #print('edited: '+organism)\n",
    "            pat_cleaned_species_dup.append(\" \".join(organism.split()[:2])) #reduce to first two words\n",
    "            #print('edited: '+\" \".join(organism.split()[:2]))\n",
    "            \n",
    "        #2 words = 2 words\n",
    "        else: \n",
    "            pat_cleaned_species_dup.append(organism)\n",
    "            #print('edited: '+organism)\n",
    "\n",
    "\n",
    "## take away dubplicates\n",
    "pat_cleaned_species = sorted(list(set(pat_cleaned_species_dup)))\n",
    "\n",
    "\n",
    "\n",
    "####################\n",
    "#get Obis data\n",
    "df_obis = pd.read_csv(R'X:\\5_Research\\Paul\\data\\WoRMS_marine_species.csv')\n",
    "\n",
    "\n",
    "cleaned_species_dup_obis = []\n",
    "for organism in df_obis['scientificName']:\n",
    "        #print(organism)\n",
    "\n",
    "        #1 word = word+ sp:\n",
    "        if len(organism.split()) == 1:\n",
    "            #print(organism)\n",
    "            cleaned_species_dup_obis.append(organism+' sp')\n",
    "            #print('edited: '+organism+' sp')\n",
    "        \n",
    "        #2 if '()' type name, just delete the brackets\n",
    "        elif '(' in organism and len(organism.split()) >= 3:\n",
    "            #print(organism)\n",
    "            #print('edited: '+(\" \".join(list(organism.split()[i] for i in (0,2)))))\n",
    "            cleaned_species_dup_obis.append((\" \".join(list(organism.split()[i] for i in (0,2)))))\n",
    "            \n",
    "        #3+ words == 3+ words + 2 words\n",
    "        elif len(organism.split()) >= 3 and '(' not in organism: \n",
    "            #print(organism)\n",
    "            cleaned_species_dup_obis.append(organism)\n",
    "            #print('edited: '+organism)\n",
    "            cleaned_species_dup_obis.append(\" \".join(organism.split()[:2])) #reduce to first two words\n",
    "            #print('edited: '+\" \".join(organism.split()[:2]))\n",
    "            \n",
    "        #2 words = 2 words\n",
    "        elif len(organism.split()) == 2: \n",
    "            cleaned_species_dup_obis.append(organism)\n",
    "            #print('edited: '+organism)\n",
    "        \n",
    "        else: \n",
    "            print('AJJJJJJJJJJJJJ')\n",
    "            #print(organism)\n",
    "\n",
    "\n",
    "## take out duplicates\n",
    "cleaned_species_obis = sorted(list(set(cleaned_species_dup_obis)))\n",
    "            \n",
    "\n",
    "#############\n",
    "#merge marine species strings together\n",
    "complete_marine_species = cleaned_species_obis + pat_cleaned_species\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############\n",
    "#match marine species strings with organism name in WILDSI\n",
    "# for now I am merging directly with ENA because there are more matches than with the standardized taxonomic names. but have to improve that anyway\n",
    "species_names_set = set(df['ORGANISM'])\n",
    "\n",
    "matching_species_edited =  [x for x in complete_marine_species if x in species_names_set]\n",
    "\n",
    "#only obis\n",
    "#len([x for x in cleaned_species_obis if x in species_names_set])\n",
    "\n",
    "#only patent\n",
    "#len([x for x in pat_cleaned_species if x in species_names_set])\n",
    "\n",
    "#len(species_names_set)\n",
    "\n",
    "marine_dict = {}\n",
    "count = 1\n",
    "for spec in species_names_set:\n",
    "    if spec in matching_species_edited: \n",
    "        marine_dict[spec] = 1\n",
    "    else: \n",
    "        marine_dict[spec] = 0\n",
    "    count = count+1\n",
    "    if count == 300000: \n",
    "        print(300000)\n",
    "    if count == 600000:\n",
    "        print(600000)\n",
    "    if count == 1200000:\n",
    "        print(1200000)\n",
    "\n",
    "df['marine'] = df['ORGANISM'].map(marine_dict) \n",
    "\n",
    "\n",
    "#if using the standardized taxons\n",
    "#df_final = pd.merge(df, df_species[['Taxid','marine']].rename(columns = {'Taxid':'TAXID'}), on = 'TAXID', how = 'left')\n",
    "#df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a494-nipw010\\AppData\\Local\\Temp\\ipykernel_9384\\3873053496.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_ncbi_lineage_with_iucn['redlistCategory'].fillna('Not assessed', inplace=True)\n",
      "C:\\Users\\a494-nipw010\\AppData\\Local\\Temp\\ipykernel_9384\\3873053496.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ncbi_lineage_with_iucn_assessed['Aggregated_Category'] = df_ncbi_lineage_with_iucn_assessed['redlistCategory'].map(category_mapping)\n"
     ]
    }
   ],
   "source": [
    "#erik's selection --- need to create the datasets first\n",
    "df_iucn = pd.read_csv(path+r'raw_data/2024-12-11_IUCN_global_assessment_all_categories_simple_summary.csv', index_col = 0)\n",
    "df_wildsi_and_ncbi = pd.read_csv(path+r'processed_data/2024-08-28_df_wildsi_with_ncbi_lineage.csv', index_col = 0)\n",
    "\n",
    "df_wildsi_and_ncbi_only_species = df_wildsi_and_ncbi[df_wildsi_and_ncbi['Rank'] == 'SPECIES']\n",
    "df_wildsi_and_ncbi_only_species_with_iucn_categories = df_wildsi_and_ncbi_only_species[(df_wildsi_and_ncbi_only_species['CODE'] == 'PLN') | (df_wildsi_and_ncbi_only_species['Kingdom name'].isin(['Metazoa', 'Fungi']))]\n",
    "\n",
    "category_mapping = {  \n",
    "    'Critically Endangered': 'Threatened',  \n",
    "    'Endangered': 'Threatened',  \n",
    "    'Vulnerable': 'Threatened',  \n",
    "    'Near Threatened': 'Lower Risk',  \n",
    "    'Least Concern': 'Lower Risk',  \n",
    "    'Data Deficient': 'Lower Risk',\n",
    "    'Lower Risk/least concern': 'Lower Risk',\n",
    "    'Lower Risk/near threatened': 'Lower Risk',\n",
    "    'Lower Risk/conservation dependent': 'Lower Risk',\n",
    "    'Extinct': 'Extinct',  \n",
    "    'Extinct in the Wild': 'Extinct',\n",
    "    'Data Deficient': 'Data Deficient',\n",
    "    'Not assessed': 'Not assessed'\n",
    "}  \n",
    "\n",
    "df_iucn_selected = df_iucn[['internalTaxonId', 'scientificName', 'populationTrend', 'redlistCategory']]\n",
    "df_iucn_selected.columns = ['internalTaxonId', 'Species name', 'populationTrend', 'redlistCategory']\n",
    "df_ncbi_lineage_with_iucn = pd.merge(df_wildsi_and_ncbi_only_species_with_iucn_categories, df_iucn_selected, on='Species name', how='left')\n",
    "df_ncbi_lineage_with_iucn['redlistCategory'].fillna('Not assessed', inplace=True)\n",
    "df_ncbi_lineage_with_iucn_assessed = df_ncbi_lineage_with_iucn\n",
    "df_ncbi_lineage_with_iucn_assessed = df_ncbi_lineage_with_iucn[df_ncbi_lineage_with_iucn['redlistCategory'] != 'Not assessed']\n",
    "df_ncbi_lineage_with_iucn_assessed['Aggregated_Category'] = df_ncbi_lineage_with_iucn_assessed['redlistCategory'].map(category_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n",
      "600000\n",
      "1200000\n"
     ]
    }
   ],
   "source": [
    "marine_phyla = ['Arthropoda', 'Mollusca', 'Cnidaria', 'Annelida', 'Echinodermata', 'Chordata']\n",
    "Arthropoda_groups = ['crustaceans', 'amphipods', 'isopods', 'horseshoe crabs']\n",
    "Mollusca_groups = ['gastropods', 'bivalves', 'cephalopods']\n",
    "Cnidaria_groups = ['stony corals', 'hydrozoans', 'blue corals', 'soft corals', 'sea pens', 'sea anemones', 'mat anemones']\n",
    "Annelida_groups = ['segmented worms']\n",
    "Echinodermata_groups = ['sea cucumbers', 'starfish', 'sea urchins']\n",
    "Chordata_groups = ['bony fishes', 'sharks & rays', 'turtles', 'whales & dolphins', 'chimaeras', 'lampreys', 'hagfishes', 'even-toed ungulates & whales', 'coelacanths', 'lungfishes']\n",
    "\n",
    "#df_ncbi_lineage_with_iucn_assessed_arthropoda['Group name'].value_counts()\n",
    "\n",
    "phylum_groups = {  \n",
    "    'Arthropoda': Arthropoda_groups,  \n",
    "    'Mollusca': Mollusca_groups,  \n",
    "    'Cnidaria': Cnidaria_groups,  \n",
    "    'Annelida': Annelida_groups,  \n",
    "    'Echinodermata': Echinodermata_groups,  \n",
    "    'Chordata': Chordata_groups  \n",
    "}  \n",
    "\n",
    "# Filter the DataFrame based on phylum and group names  \n",
    "marine_DSI = df_ncbi_lineage_with_iucn_assessed[  \n",
    "    df_ncbi_lineage_with_iucn_assessed['Phylum name'].isin(marine_phyla) &   \n",
    "    df_ncbi_lineage_with_iucn_assessed['Group name'].isin(  \n",
    "        [group for groups in phylum_groups.values() for group in groups]  \n",
    "    )  \n",
    "]  \n",
    "\n",
    "\n",
    "#Label df with the marine_alternativ label\n",
    "complete_marine_species_alt = marine_DSI['ORGANISM']\n",
    "matching_species_edited_alt =  [x for x in complete_marine_species_alt if x in species_names_set]\n",
    "\n",
    "marine_alt_dict = {}\n",
    "count = 1\n",
    "for spec in species_names_set:\n",
    "    if spec in matching_species_edited_alt: \n",
    "        marine_alt_dict[spec] = 1\n",
    "    else: \n",
    "        marine_alt_dict[spec] = 0\n",
    "    count = count+1\n",
    "    if count == 300000: \n",
    "        print(300000)\n",
    "    if count == 600000:\n",
    "        print(600000)\n",
    "    if count == 1200000:\n",
    "        print(1200000)\n",
    "\n",
    "df['marine_alt'] = df['ORGANISM'].map(marine_alt_dict) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare both marine and marine_alt versions\n",
    "all_marine_species = list(set(list(complete_marine_species_alt) + complete_marine_species))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15708"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(complete_marine_species_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132083"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(complete_marine_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141059"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_marine_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n",
      "600000\n",
      "1200000\n"
     ]
    }
   ],
   "source": [
    "#label all marine species (merge of old marine species list and new one created by Erik) \n",
    "matching_species_edited_all =  [x for x in all_marine_species if x in species_names_set]\n",
    "\n",
    "marine_all_dict = {}\n",
    "count = 1\n",
    "for spec in species_names_set:\n",
    "    if spec in matching_species_edited_all: \n",
    "        marine_all_dict[spec] = 1\n",
    "    else: \n",
    "        marine_all_dict[spec] = 0\n",
    "    count = count+1\n",
    "    if count == 300000: \n",
    "        print(300000)\n",
    "    if count == 600000:\n",
    "        print(600000)\n",
    "    if count == 1200000:\n",
    "        print(1200000)\n",
    "\n",
    "df['marine_all'] = df['ORGANISM'].map(marine_all_dict) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCESSION</th>\n",
       "      <th>PRIMARY_PMID</th>\n",
       "      <th>PRIMARY_DOI</th>\n",
       "      <th>PRIMARY_PMCID</th>\n",
       "      <th>TAXID</th>\n",
       "      <th>ORGANISM</th>\n",
       "      <th>id_select</th>\n",
       "      <th>skingdom</th>\n",
       "      <th>species</th>\n",
       "      <th>genus</th>\n",
       "      <th>class</th>\n",
       "      <th>crops</th>\n",
       "      <th>pathogens</th>\n",
       "      <th>marine</th>\n",
       "      <th>marine_alt</th>\n",
       "      <th>marine_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ML186446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74909.0</td>\n",
       "      <td>Cuora amboinensis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>Cuora amboinensis</td>\n",
       "      <td>Cuora</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>KM077217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1569789.0</td>\n",
       "      <td>Stegastes sanctipauli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>Stegastes sanctipauli</td>\n",
       "      <td>Stegastes</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>MK001165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178576.0</td>\n",
       "      <td>Labeobarbus gananensis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>Labeobarbus gananensis</td>\n",
       "      <td>Labeobarbus</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>KQ052229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9923.0</td>\n",
       "      <td>Capra aegagrus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>Capra aegagrus</td>\n",
       "      <td>Capra</td>\n",
       "      <td>Mammalia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>MF372680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70285.0</td>\n",
       "      <td>Thymallus arcticus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>Thymallus arcticus</td>\n",
       "      <td>Thymallus</td>\n",
       "      <td>Actinopteri</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36740200</th>\n",
       "      <td>MW143048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2924052.0</td>\n",
       "      <td>Bythaelurus lutarius</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>Bythaelurus lutarius</td>\n",
       "      <td>Bythaelurus</td>\n",
       "      <td>Chondrichthyes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36749374</th>\n",
       "      <td>MW143050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2924052.0</td>\n",
       "      <td>Bythaelurus lutarius</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>Bythaelurus lutarius</td>\n",
       "      <td>Bythaelurus</td>\n",
       "      <td>Chondrichthyes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36754581</th>\n",
       "      <td>MW673776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143294.0</td>\n",
       "      <td>Anodonta anatina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>Anodonta anatina</td>\n",
       "      <td>Anodonta</td>\n",
       "      <td>Bivalvia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36755323</th>\n",
       "      <td>MW675805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143294.0</td>\n",
       "      <td>Anodonta anatina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>Anodonta anatina</td>\n",
       "      <td>Anodonta</td>\n",
       "      <td>Bivalvia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36759969</th>\n",
       "      <td>MW143057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2924052.0</td>\n",
       "      <td>Bythaelurus lutarius</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eukaryota</td>\n",
       "      <td>Bythaelurus lutarius</td>\n",
       "      <td>Bythaelurus</td>\n",
       "      <td>Chondrichthyes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>564695 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ACCESSION  PRIMARY_PMID PRIMARY_DOI PRIMARY_PMCID      TAXID  \\\n",
       "45        ML186446           NaN         NaN           NaN    74909.0   \n",
       "115       KM077217           NaN         NaN           NaN  1569789.0   \n",
       "191       MK001165           NaN         NaN           NaN   178576.0   \n",
       "504       KQ052229           NaN         NaN           NaN     9923.0   \n",
       "561       MF372680           NaN         NaN           NaN    70285.0   \n",
       "...            ...           ...         ...           ...        ...   \n",
       "36740200  MW143048           NaN         NaN           NaN  2924052.0   \n",
       "36749374  MW143050           NaN         NaN           NaN  2924052.0   \n",
       "36754581  MW673776           NaN         NaN           NaN   143294.0   \n",
       "36755323  MW675805           NaN         NaN           NaN   143294.0   \n",
       "36759969  MW143057           NaN         NaN           NaN  2924052.0   \n",
       "\n",
       "                        ORGANISM id_select   skingdom                 species  \\\n",
       "45             Cuora amboinensis       NaN  Eukaryota       Cuora amboinensis   \n",
       "115        Stegastes sanctipauli       NaN  Eukaryota   Stegastes sanctipauli   \n",
       "191       Labeobarbus gananensis       NaN  Eukaryota  Labeobarbus gananensis   \n",
       "504               Capra aegagrus       NaN  Eukaryota          Capra aegagrus   \n",
       "561           Thymallus arcticus       NaN  Eukaryota      Thymallus arcticus   \n",
       "...                          ...       ...        ...                     ...   \n",
       "36740200    Bythaelurus lutarius       NaN  Eukaryota    Bythaelurus lutarius   \n",
       "36749374    Bythaelurus lutarius       NaN  Eukaryota    Bythaelurus lutarius   \n",
       "36754581        Anodonta anatina       NaN  Eukaryota        Anodonta anatina   \n",
       "36755323        Anodonta anatina       NaN  Eukaryota        Anodonta anatina   \n",
       "36759969    Bythaelurus lutarius       NaN  Eukaryota    Bythaelurus lutarius   \n",
       "\n",
       "                genus           class  crops  pathogens  marine  marine_alt  \\\n",
       "45              Cuora             NaN      0          0       0           1   \n",
       "115         Stegastes     Actinopteri      0          0       0           1   \n",
       "191       Labeobarbus     Actinopteri      0          0       0           1   \n",
       "504             Capra        Mammalia      0          0       0           1   \n",
       "561         Thymallus     Actinopteri      0          0       0           1   \n",
       "...               ...             ...    ...        ...     ...         ...   \n",
       "36740200  Bythaelurus  Chondrichthyes      0          0       0           1   \n",
       "36749374  Bythaelurus  Chondrichthyes      0          0       0           1   \n",
       "36754581     Anodonta        Bivalvia      0          0       0           1   \n",
       "36755323     Anodonta        Bivalvia      0          0       0           1   \n",
       "36759969  Bythaelurus  Chondrichthyes      0          0       0           1   \n",
       "\n",
       "          marine_all  \n",
       "45                 1  \n",
       "115                1  \n",
       "191                1  \n",
       "504                1  \n",
       "561                1  \n",
       "...              ...  \n",
       "36740200           1  \n",
       "36749374           1  \n",
       "36754581           1  \n",
       "36755323           1  \n",
       "36759969           1  \n",
       "\n",
       "[564695 rows x 16 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['marine'] == 0) & (df['marine_alt'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### alt but not in original: \n",
    "1) wrong: Amboina box turtle --> freshwater not really saltwater it seems https://en.wikipedia.org/wiki/Amboina_box_turtle\n",
    "2) correct: Stegastes sanctipauli --> marine fish https://en.wikipedia.org/wiki/Stegastes_sanctipauli\n",
    "3) wrong: Labeobarbus gananensis --> bit unclear but seemingly a freshwater fish\n",
    "4) wrong: Capra aegagrus --> simply a goat, not aquatic at all --> in here under group ungulates & whales for some reason\n",
    "5) wrong: Thymallus arcticus\t--> freshwater fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv(path+R'processed_data/acc_id.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104009"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_clean['id_select']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the difference in numbers is probably because for some I could not get info from the Lens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_clean[['ACCESSION','id_select']], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ACCESSION','id_select','TAXID','species','skingdom','crops','pathogens', 'marine', 'marine_alt', 'marine_all']].to_csv(path+R'processed_data/gr_types_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Add everything to the regression df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a494-nipw010\\AppData\\Local\\Temp\\ipykernel_18696\\3509829030.py:1: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path+R'processed_data/gr_types.csv', index_col = 0)\n"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(path+R'processed_data/gr_types.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extract_com = pd.read_csv(path+R'processed_data\\extractivism_com3.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform skingdom column into binary variables\n",
    "df_skingdom_dummies = pd.get_dummies(df['skingdom'], dtype=float)\n",
    "df['Archaea'] = df_skingdom_dummies['Archaea']\n",
    "df['Bacteria'] = df_skingdom_dummies['Bacteria']\n",
    "df['Viruses'] = df_skingdom_dummies['Viruses']\n",
    "df['Eukaryota'] = df_skingdom_dummies['Eukaryota']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n",
      "30700\n",
      "30800\n",
      "30900\n",
      "31000\n",
      "31100\n",
      "31200\n",
      "31300\n",
      "31400\n",
      "31500\n",
      "31600\n",
      "31700\n",
      "31800\n",
      "31900\n",
      "32000\n",
      "32100\n",
      "32200\n",
      "32300\n",
      "32400\n",
      "32500\n",
      "32600\n",
      "32700\n",
      "32800\n",
      "32900\n",
      "33000\n",
      "33100\n",
      "33200\n",
      "33300\n",
      "33400\n",
      "33500\n",
      "33600\n",
      "33700\n",
      "33800\n",
      "33900\n",
      "34000\n",
      "34100\n",
      "34200\n",
      "34300\n",
      "34400\n",
      "34500\n",
      "34600\n",
      "34700\n",
      "34800\n",
      "34900\n",
      "35000\n",
      "35100\n",
      "35200\n",
      "35300\n",
      "35400\n",
      "35500\n",
      "35600\n",
      "35700\n",
      "35800\n",
      "35900\n",
      "36000\n",
      "36100\n",
      "36200\n",
      "36300\n",
      "36400\n",
      "36500\n",
      "36600\n",
      "36700\n",
      "36800\n",
      "36900\n",
      "37000\n",
      "37100\n",
      "37200\n",
      "37300\n",
      "37400\n",
      "37500\n",
      "37600\n",
      "37700\n",
      "37800\n",
      "37900\n",
      "38000\n",
      "38100\n",
      "38200\n",
      "38300\n",
      "38400\n",
      "38500\n",
      "38600\n",
      "38700\n",
      "38800\n",
      "38900\n",
      "39000\n",
      "39100\n",
      "39200\n",
      "39300\n",
      "39400\n",
      "39500\n",
      "39600\n",
      "39700\n",
      "39800\n",
      "39900\n",
      "40000\n",
      "40100\n",
      "40200\n",
      "40300\n",
      "40400\n",
      "40500\n",
      "40600\n",
      "40700\n",
      "40800\n",
      "40900\n",
      "41000\n",
      "41100\n",
      "41200\n",
      "41300\n",
      "41400\n",
      "41500\n",
      "41600\n",
      "41700\n",
      "41800\n",
      "41900\n",
      "42000\n",
      "42100\n",
      "42200\n",
      "42300\n",
      "42400\n",
      "42500\n",
      "42600\n",
      "42700\n",
      "42800\n",
      "42900\n",
      "43000\n",
      "43100\n",
      "43200\n",
      "43300\n",
      "43400\n",
      "43500\n",
      "43600\n",
      "43700\n",
      "43800\n",
      "43900\n",
      "44000\n",
      "44100\n",
      "44200\n",
      "44300\n",
      "44400\n",
      "44500\n",
      "44600\n",
      "44700\n",
      "44800\n",
      "44900\n",
      "45000\n",
      "45100\n",
      "45200\n",
      "45300\n",
      "45400\n",
      "45500\n",
      "45600\n",
      "45700\n",
      "45800\n",
      "45900\n",
      "46000\n",
      "46100\n",
      "46200\n",
      "46300\n",
      "46400\n",
      "46500\n",
      "46600\n",
      "46700\n",
      "46800\n",
      "46900\n",
      "47000\n",
      "47100\n",
      "47200\n",
      "47300\n",
      "47400\n",
      "47500\n",
      "47600\n",
      "47700\n",
      "47800\n",
      "47900\n",
      "48000\n",
      "48100\n",
      "48200\n",
      "48300\n",
      "48400\n",
      "48500\n",
      "48600\n",
      "48700\n",
      "48800\n",
      "48900\n",
      "49000\n",
      "49100\n",
      "49200\n",
      "49300\n",
      "49400\n",
      "49500\n",
      "49600\n",
      "49700\n",
      "49800\n",
      "49900\n",
      "50000\n",
      "50100\n",
      "50200\n",
      "50300\n",
      "50400\n",
      "50500\n",
      "50600\n",
      "50700\n",
      "50800\n",
      "50900\n",
      "51000\n",
      "51100\n",
      "51200\n",
      "51300\n",
      "51400\n",
      "51500\n",
      "51600\n",
      "51700\n",
      "51800\n",
      "51900\n",
      "52000\n",
      "52100\n",
      "52200\n",
      "52300\n",
      "52400\n",
      "52500\n",
      "52600\n",
      "52700\n",
      "52800\n",
      "52900\n",
      "53000\n",
      "53100\n",
      "53200\n",
      "53300\n",
      "53400\n",
      "53500\n",
      "53600\n",
      "53700\n",
      "53800\n",
      "53900\n",
      "54000\n",
      "54100\n",
      "54200\n",
      "54300\n",
      "54400\n",
      "54500\n",
      "54600\n",
      "54700\n",
      "54800\n",
      "54900\n",
      "55000\n",
      "55100\n",
      "55200\n",
      "55300\n",
      "55400\n",
      "55500\n",
      "55600\n",
      "55700\n",
      "55800\n",
      "55900\n",
      "56000\n",
      "56100\n",
      "56200\n",
      "56300\n",
      "56400\n",
      "56500\n",
      "56600\n",
      "56700\n",
      "56800\n",
      "56900\n",
      "57000\n",
      "57100\n",
      "57200\n",
      "57300\n",
      "57400\n",
      "57500\n",
      "57600\n",
      "57700\n",
      "57800\n",
      "57900\n",
      "58000\n",
      "58100\n",
      "58200\n",
      "58300\n",
      "58400\n",
      "58500\n",
      "58600\n",
      "58700\n",
      "58800\n",
      "58900\n",
      "59000\n",
      "59100\n",
      "59200\n",
      "59300\n",
      "59400\n",
      "59500\n",
      "59600\n",
      "59700\n",
      "59800\n",
      "59900\n",
      "60000\n",
      "60100\n",
      "60200\n",
      "60300\n",
      "60400\n",
      "60500\n",
      "60600\n",
      "60700\n",
      "60800\n",
      "60900\n",
      "61000\n",
      "61100\n",
      "61200\n",
      "61300\n",
      "61400\n",
      "61500\n",
      "61600\n",
      "61700\n",
      "61800\n",
      "61900\n",
      "62000\n",
      "62100\n",
      "62200\n",
      "62300\n",
      "62400\n",
      "62500\n",
      "62600\n",
      "62700\n",
      "62800\n",
      "62900\n",
      "63000\n",
      "63100\n",
      "63200\n",
      "63300\n",
      "63400\n",
      "63500\n",
      "63600\n",
      "63700\n",
      "63800\n",
      "63900\n",
      "64000\n",
      "64100\n",
      "64200\n",
      "64300\n",
      "64400\n",
      "64500\n",
      "64600\n",
      "64700\n",
      "64800\n",
      "64900\n",
      "65000\n",
      "65100\n",
      "65200\n",
      "65300\n",
      "65400\n",
      "65500\n",
      "65600\n",
      "65700\n",
      "65800\n",
      "65900\n",
      "66000\n",
      "66100\n",
      "66200\n",
      "66300\n",
      "66400\n",
      "66500\n",
      "66600\n",
      "66700\n",
      "66800\n",
      "66900\n",
      "67000\n",
      "67100\n",
      "67200\n",
      "67300\n",
      "67400\n",
      "67500\n",
      "67600\n",
      "67700\n",
      "67800\n",
      "67900\n",
      "68000\n",
      "68100\n",
      "68200\n",
      "68300\n",
      "68400\n",
      "68500\n",
      "68600\n",
      "68700\n",
      "68800\n",
      "68900\n",
      "69000\n",
      "69100\n",
      "69200\n",
      "69300\n",
      "69400\n",
      "69500\n",
      "69600\n",
      "69700\n",
      "69800\n",
      "69900\n",
      "70000\n",
      "70100\n",
      "70200\n",
      "70300\n",
      "70400\n",
      "70500\n",
      "70600\n",
      "70700\n",
      "70800\n",
      "70900\n",
      "71000\n",
      "71100\n",
      "71200\n",
      "71300\n",
      "71400\n",
      "71500\n",
      "71600\n",
      "71700\n",
      "71800\n",
      "71900\n",
      "72000\n",
      "72100\n",
      "72200\n",
      "72300\n",
      "72400\n",
      "72500\n",
      "72600\n",
      "72700\n",
      "72800\n",
      "72900\n",
      "73000\n",
      "73100\n",
      "73200\n",
      "73300\n",
      "73400\n",
      "73500\n",
      "73600\n",
      "73700\n",
      "73800\n",
      "73900\n",
      "74000\n",
      "74100\n",
      "74200\n",
      "74300\n",
      "74400\n",
      "74500\n",
      "74600\n",
      "74700\n",
      "74800\n",
      "74900\n",
      "75000\n",
      "75100\n",
      "75200\n",
      "75300\n",
      "75400\n",
      "75500\n",
      "75600\n",
      "75700\n",
      "75800\n",
      "75900\n",
      "76000\n",
      "76100\n",
      "76200\n",
      "76300\n",
      "76400\n",
      "76500\n",
      "76600\n",
      "76700\n",
      "76800\n",
      "76900\n",
      "77000\n",
      "77100\n",
      "77200\n",
      "77300\n",
      "77400\n",
      "77500\n",
      "77600\n",
      "77700\n",
      "77800\n",
      "77900\n",
      "78000\n",
      "78100\n",
      "78200\n",
      "78300\n",
      "78400\n",
      "78500\n",
      "78600\n",
      "78700\n",
      "78800\n",
      "78900\n",
      "79000\n",
      "79100\n",
      "79200\n",
      "79300\n",
      "79400\n",
      "79500\n",
      "79600\n",
      "79700\n",
      "79800\n",
      "79900\n",
      "80000\n",
      "80100\n",
      "80200\n",
      "80300\n",
      "80400\n",
      "80500\n",
      "80600\n",
      "80700\n",
      "80800\n",
      "80900\n",
      "81000\n",
      "81100\n",
      "81200\n",
      "81300\n",
      "81400\n",
      "81500\n",
      "81600\n",
      "81700\n",
      "81800\n",
      "81900\n",
      "82000\n",
      "82100\n",
      "82200\n",
      "82300\n",
      "82400\n",
      "82500\n",
      "82600\n",
      "82700\n",
      "82800\n",
      "82900\n",
      "83000\n",
      "83100\n",
      "83200\n",
      "83300\n",
      "83400\n",
      "83500\n",
      "83600\n",
      "83700\n",
      "83800\n",
      "83900\n",
      "84000\n",
      "84100\n",
      "84200\n",
      "84300\n",
      "84400\n",
      "84500\n",
      "84600\n",
      "84700\n",
      "84800\n",
      "84900\n",
      "85000\n",
      "85100\n",
      "85200\n",
      "85300\n",
      "85400\n",
      "85500\n",
      "85600\n",
      "85700\n",
      "85800\n",
      "85900\n",
      "86000\n",
      "86100\n",
      "86200\n",
      "86300\n",
      "86400\n",
      "86500\n",
      "86600\n",
      "86700\n",
      "86800\n",
      "86900\n",
      "87000\n",
      "87100\n",
      "87200\n",
      "87300\n",
      "87400\n",
      "87500\n",
      "87600\n",
      "87700\n",
      "87800\n",
      "87900\n",
      "88000\n",
      "88100\n",
      "88200\n",
      "88300\n",
      "88400\n",
      "88500\n",
      "88600\n",
      "88700\n",
      "88800\n",
      "88900\n",
      "89000\n",
      "89100\n",
      "89200\n",
      "89300\n",
      "89400\n",
      "89500\n",
      "89600\n",
      "89700\n",
      "89800\n",
      "89900\n",
      "90000\n",
      "90100\n",
      "90200\n",
      "90300\n",
      "90400\n",
      "90500\n",
      "90600\n",
      "90700\n",
      "90800\n",
      "90900\n",
      "91000\n",
      "91100\n",
      "91200\n",
      "91300\n",
      "91400\n",
      "91500\n",
      "91600\n",
      "91700\n",
      "91800\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to store entailment columns\n",
    "entailment_columns = ['Eukaryota','Bacteria','Archaea','Viruses', 'marine', 'pathogens', 'crops']  # Add other categories as needed, 'marine', 'crops' , 'Viruses',\n",
    "entails = {col: [] for col in entailment_columns}\n",
    "\n",
    "# Group the df_ids DataFrame by 'id_select' to perform calculations in bulk\n",
    "grouped_df = df.groupby('id_select')\n",
    "selected_ids = list(set(df['id_select']))\n",
    "\n",
    "# For each identifier, calculate entailments for all categories at once\n",
    "nr = 1\n",
    "for identifier in df_extract_com['id_select']:\n",
    "    if identifier in selected_ids:\n",
    "        # Select the group for the current identifier\n",
    "        df_id_select = grouped_df.get_group(identifier)\n",
    "\n",
    "        # Check each category and store entailment as 1 if any rows contain a positive value\n",
    "        for category in entailment_columns:\n",
    "            entails[category].append(int((df_id_select[category] > 0).any()))\n",
    "    else: \n",
    "        for category in entailment_columns:\n",
    "            entails[category].append('flawed_id')\n",
    "    \n",
    "    if nr in range(0,100000,100):\n",
    "        print(nr)\n",
    "    nr = nr+1\n",
    "    \n",
    "# Convert dictionary to DataFrame if needed\n",
    "entails_df = pd.DataFrame(entails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extract_com_type = df_extract_com.copy()\n",
    "df_extract_com_type = df_extract_com_type.join(entails_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extract_com_type.to_csv(path+R'processed_data\\extractivism_com3_type_test3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nocov = df[df['TAXID'] != 2697049.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_pubs = []\n",
    "for pub in list(df['PRIMARY_PMID']):\n",
    "    if pd.isna(pub):\n",
    "        has_pubs.append('no_pub')\n",
    "    else:\n",
    "        has_pubs.append('has_pub')\n",
    "df['has_pub'] = has_pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_coors = []\n",
    "for coor in list(df['LAT_LON']):\n",
    "    if pd.isna(coor):\n",
    "        has_coors.append('no_coor')\n",
    "    else:\n",
    "        has_coors.append('has_coor')\n",
    "df['has_coor'] = has_coors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share_vis = df[['has_pub','skingdom','genus']].dropna()\n",
    "df_share_vis['count'] = 1\n",
    "# Create a column for percentage shares\n",
    "#df_share_vis['percentage'] = df_share_vis['count'] / df_share_vis['count'].sum() * 100\n",
    "\n",
    "# Create the treemap\n",
    "fig = px.treemap(\n",
    "    df_share_vis, \n",
    "    path=['has_pub','skingdom','genus'],  # Hierarchical categories\n",
    "    values='count',  # Values for sizes\n",
    "    color='skingdom',  # Optional: Color based on values\n",
    "    #hover_data={'percentage': ':.2f%'},  # Show percentage shares on hover\n",
    ")\n",
    "\n",
    "# Update layout to show percentage shares in labels\n",
    "fig.update_traces(textinfo='label+value+percent entry')\n",
    "fig.update_traces(root_color=\"lightgrey\")\n",
    "\n",
    "# Show the treemap\n",
    "fig.show()\n",
    "\n",
    "# Save as a static image \n",
    "fig.write_image(path+R\"plots\\species_treemap_genus_pubs.svg\")  # You can also use .jpg, .pdf, .png\n",
    "fig.write_image(path+R\"plots\\species_treemap_genus_pubs.pdf\")  # You can also use .jpg, .pdf, .png\n",
    "# OR, save as an interactive HTML file\n",
    "#fig.write_html(\"treemap_plot.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share_vis = df[['has_pub','skingdom','genus']].dropna()\n",
    "df_share_vis['count'] = 1\n",
    "# Create a column for percentage shares\n",
    "#df_share_vis['percentage'] = df_share_vis['count'] / df_share_vis['count'].sum() * 100\n",
    "\n",
    "# Create the treemap\n",
    "fig = px.treemap(\n",
    "    df_share_vis, \n",
    "    path=['skingdom','genus'],  # Hierarchical categories\n",
    "    values='count',  # Values for sizes\n",
    "    color='skingdom',  # Optional: Color based on values\n",
    "    #hover_data={'percentage': ':.2f%'},  # Show percentage shares on hover\n",
    ")\n",
    "\n",
    "# Update layout to show percentage shares in labels\n",
    "fig.update_traces(textinfo='label+value+percent entry')\n",
    "fig.update_traces(root_color=\"lightgrey\")\n",
    "fig.update_layout(\n",
    "    width=1200,  # Set the desired width\n",
    "    height=800   # Set the desired height\n",
    ")\n",
    "# Show the treemap\n",
    "fig.show()\n",
    "\n",
    "# Save as a static image \n",
    "fig.write_image(path+R\"plots\\species_treemap_genus.svg\")  # You can also use .jpg, .pdf, .png\n",
    "fig.write_image(path+R\"plots\\species_treemap_genus.pdf\")  # You can also use .jpg, .pdf, .png\n",
    "# OR, save as an interactive HTML file\n",
    "#fig.write_html(\"treemap_plot.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class\n",
    "df_share_vis = df[['has_pub','skingdom','class']].dropna()\n",
    "df_share_vis['count'] = 1\n",
    "# Create a column for percentage shares\n",
    "#df_share_vis['percentage'] = df_share_vis['count'] / df_share_vis['count'].sum() * 100\n",
    "\n",
    "# Create the treemap\n",
    "fig = px.treemap(\n",
    "    df_share_vis, \n",
    "    path=['has_pub','skingdom','class'],  # Hierarchical categories\n",
    "    values='count',  # Values for sizes\n",
    "    color='skingdom',  # Optional: Color based on values\n",
    "    #hover_data={'percentage': ':.2f%'},  # Show percentage shares on hover\n",
    ")\n",
    "\n",
    "# Update layout to show percentage shares in labels\n",
    "fig.update_traces(textinfo='label+value+percent entry')\n",
    "fig.update_traces(root_color=\"lightgrey\")\n",
    "\n",
    "# Show the treemap\n",
    "fig.show()\n",
    "\n",
    "# Save as a static image \n",
    "fig.write_image(path+R\"plots\\species_treemap_class_pubs.svg\")  # You can also use .jpg, .pdf, .png\n",
    "fig.write_image(path+R\"plots\\species_treemap_class_pubs.pdf\")  # You can also use .jpg, .pdf, .png\n",
    "# OR, save as an interactive HTML file\n",
    "#fig.write_html(\"treemap_plot.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_share_vis = df[['has_pub','skingdom','class']].dropna()\n",
    "df_share_vis['count'] = 1\n",
    "# Create a column for percentage shares\n",
    "#df_share_vis['percentage'] = df_share_vis['count'] / df_share_vis['count'].sum() * 100\n",
    "\n",
    "# Create the treemap\n",
    "fig = px.treemap(\n",
    "    df_share_vis, \n",
    "    path=['skingdom','class'],  # Hierarchical categories\n",
    "    values='count',  # Values for sizes\n",
    "    color='skingdom',  # Optional: Color based on values\n",
    "    #hover_data={'percentage': ':.2f%'},  # Show percentage shares on hover\n",
    ")\n",
    "\n",
    "# Update layout to show percentage shares in labels\n",
    "fig.update_traces(textinfo='label+value+percent entry')\n",
    "fig.update_traces(root_color=\"lightgrey\")\n",
    "\n",
    "# Show the treemap\n",
    "fig.show()\n",
    "\n",
    "# Save as a static image \n",
    "fig.write_image(path+R\"plots\\species_treemap_class.svg\")  # You can also use .jpg, .pdf, .png\n",
    "fig.write_image(path+R\"plots\\species_treemap_class.pdf\")  # You can also use .jpg, .pdf, .png\n",
    "# OR, save as an interactive HTML file\n",
    "#fig.write_html(\"treemap_plot.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
